### 概述(96-199高级篇)
- 了解mysql就会明白为什么这么划分知识章节
- `架构篇` `索引及调优篇` `事务篇` `日志与备份篇`
- `索引` `mvcc` `锁` `主从`


### 架构篇(mysql软件架构)
**mysql安装使用**
Linux下mysql安装/使用/卸载/远程连接Linux下mysql服务器  
mysql密码安全性  
xshell远程连接Linux系统 类似navicat连接mysql服务器  

**字符集**
字符集：顾名思义 字符的集合 字符库!!!  
mysql8默认字符集utf8 如果表的字符集是不包含中文的字符集则不能添加中文 库字符集改了 新建表若不显式指定字符集则自动跟随库的字符集!!!  
库/表的字符集 charset  
去配置文件改mysql server的默认字符集  
改默认字符集后已有的库/表的字符集不会变 建表/库时可以指定字符集 但一般不用显式指定 用默认即可  
字符集级别：服务器级别、库级别、表级别、列级别 改的时候会把下级都改了 上下级关系  
类似bip系统级别、租户级别  
字符集、比较规则、存储引擎 建数据库语句的后面有标识 ENGINE=INNODB default charset=utf8  
请求到响应过程中字符集的变化  

**sql大小写敏感相关**  
**sql_mode**  
sql语句语法的校验严格程度 宽松模式 严格模式 数据库迁移时为了执行sql的通过率 需要严格模式  


**mysql软件目录结构**(从`文件系统`的角度看mysql,`mysql物理结构`)
mysql安装到Linux后是一个目录 熟悉Linux下mysql目录结构!!!  
`mysql库:`存用户、权限信息  
`information_schema库:`存 存储过程 函数 约束等信息  
`sys库:`用于监控mysql性能  
从mysql软件目录结构(文件系统) 和数据库表 对应关系 存储引擎  
指定不同存储引擎的数据表 在磁盘文件系统中文件不一样 有些存储引擎索引和数据在外存文件中是分开存的  
视图在文件系统中怎么表示的 在哪个文件里  


**105-108 用户、角色、权限(未看)**
配置文件的使用:配置文件中有不识别的变量 mysql服务会启动失败!!!  
系统变量  

**mysql逻辑架构**(从软件实现的角度看mysql!!!类似web系统MVC结构)
mysql是c/s架构 即客户端/服务器架构 客户端可以是jdbc连接、navicat等  
mysql逻辑架构分为4层  
1. 连接层
2. 服务层
3. 存储引擎层
4. 硬件层 系统文件

mysql逻辑架构组件有：  
- `连接池` `基础服务组件` `sql接口` `解析器` `优化器(在服务层)` `插件式存储引擎` `文件系统`
存储引擎和文件系统交互  
查询不是直接在文件系统中查询并返回 而是文件系统数据加载到内存去查询 cpu和内存交互 内存和磁盘交互 cpu不和磁盘交互  
mysql存储引擎真正负责了mysql中数据的存储和提取  
mysql架构 一次查询 其实就相当于类似http访问一次后端Java应用  

**sql执行流程**(有助于索引学习、sql优化学习)
1. 从mysql系统 代码执行角度:  
客户端发送sql -> 查询缓存(已废弃) -> 解析器(词法分析 语法分析) -> 解析树 ->  
查询优化器(多种执行方式中选一个最优的执行方式 生成执行计划) -> 执行计划 ->  
执行器 -> 看是否有权限 -> 调存储引擎api!!!  
查询缓存废弃是因为缓存命中率不高  
2. 从sql语句执行过程角度:  
from -> on-> 左外连接/右外连接/内连接 -> where-> group by -> having ->  
select -> 去重 -> order by -> limit  

**数据库缓冲池**
数据在内存中的缓存即数据库缓冲池 为了减少cpu与磁盘进行io的时间  
内存加载磁盘数据是以数据页为单位加载的  
`页面置换算法`：优先加载常用数据页  
缓冲池中数据和磁盘数据会有不一致的时候 因为刷盘到磁盘是每隔一段时间进行的  

**存储引擎相关**(存储引擎在mysql逻辑架构的引擎层)
创建表时可以显式指定表的(存储)引擎 engine  
每张表可以指定不同的存储引擎 就像每辆车可以指定不同的发动机  
mysql逻辑架构之存储引擎，插件式存储引擎，存储引擎就是表的类型 过去叫表处理器  
存储引擎就是根据上层指令负责真实存/取数据的功能集合!!!  
因此不同存储引擎 存取功能是不一样的 有的存储引擎支持索引、事务，有的存储引擎不支持  
执行计划 -> 调存储引擎api -> 返回数据!!!  
mysql是存储数据的数据库，最重要的是存储引擎，这里引擎的概念，比如cpu(执行引擎)，es(搜索引擎)，mysql(存储引擎)  
不同存储引擎的表在文件系统中文件结构不同  

**这里关注两个存储引擎**
1. `InnoDB(默认存储引擎)`
2. `MyISAM存储引擎`(二者不是替代关系 各有优劣势)

**InnoDB和MyISAM的区别!!!** 事务 锁 外键 mvcc
1. myisam崩溃后无法安全恢复，是不支持事务导致的,而innodb崩溃后可以安全恢复(因为bin log日志)mysql所有存储引擎中，只有InnoDB支持事务
2. 是否支持行级锁：myisam只有表级锁，innodb有表级锁、行级锁(默认)。
3. innodb支持事务,支持数据提交回滚，因为支持事务 因此该存储引擎有优点，为了处理大量数据并发量大有优势，myisam不支持事务。
4. innodb支持外键，myisam不支持外键
5. 只有innodb支持mvcc mvcc即多版本并发控制，mvcc是一种并发控制的方法

**innodb缺点**：
1. 相比myisam存储引擎执行慢，占空间大
2. innodb处理效率差一些 数据小时比myisam慢
3. 对内存要求高 因为索引即数据 索引数据存在一个文件中 myisam 索引和数据分开存储 只加载索引 innodb全加载因此占内存大  
简单业务 资源小时用mysiam  
并发写 更大资源 事务时使用innodb  
其他存储引擎：archive，csv  


### 索引及调优篇(115-)
**索引**
`索引`是在`存储引擎`中实现的,索引就是为了提高查询性能 相当于书的目录，但也有区别  
表数据在文件系统中存储的基本单位是数据页 16KB，数据页中存储表的几条数据 行格式 行格式记录表的下一条数据的信息  
文件系统中 页之间 表数据之间 都不一定是物理连续的 是逻辑连续!!!  
学习就是让人们能透视mysql的内部 底层 是什么样子  

`索引是存储引擎用于快速找到数据的一种数据结构`，索引底层数据结构主要是：b+树、哈希 相当于书的目录  
`b+树`极其简化后就是`二叉搜索树`!!!  
`索引是一种排好序的数据结构`  
有了索引mysql存储引擎可以更快速查找数据 这里也涉及数据结构的知识点 有了索引就减少了查找数据时磁盘的io  
时间复杂度低了 mysql开发工程师设计索引就是为了加快mysql的速度 让mysql更好用  

**创建索引**
`创建索引`：建表时 INDEX(列名)  
给一个字段创建索引：为这个字段排好序 构建索引b+树 回车耗费时间和空间  
插入数据时 索引也会跟着调整 为了快可以事先删除索引 之后再加上索引!!!  
索引在添加有些约束时会隐式的创建 比如主键约束 唯一约束 外键约束等  
**索引设计原则**
- 哪些字段适合/不适合加索引!!!:去重 得排序 所以加索引好(表数据量小 且对某字段去重查询操作频繁 给该字段加索引合适)
- 索引失效的场景:
    - 全值匹配：where条件 等值 创建全的联合索引
    - 最左前缀原则 但如果查询的字段有联合索引字段 则会使用索引 结论：MySQL可以为多个字段创建索引，一个索引可以包括16个字段。对于多列索引，过滤条件要使用索引必须按照索引建立时的顺序，依次满足，一旦跳过某个字段，索引后面的字段都无法被使用。如果查询条件中没有使用这些字段中第1个字段时，多列(或联合)索引不会被使用。
    - 计算 函数 类型转换(类型不匹配)会导致索引失效 函数为什么会导致索引失效
    - 范围条件右边的列索引失效 大于小于
    - ！=对于普通索引失效
    - is not null索引失效
    - like 以%开头索引失效 b+树不知道怎么查了
    - OR 前后存在非索引的列，索引失效 根据这些去体会b+树的查询方式
    - 数据库和表的字符集统一使用utf8mb4 否则会索引失效
- 尽量选择过滤性更好的字段当索引


**索引类型**
- 从数据库物理存储角度：`聚簇索引`、`非聚簇索引`
- 从功能角度：`普通索引` `唯一索引` `主键索引` `全文索引(全文检索)`
- 从作用字段个数角度：`单列索引` `联合索引(组合索引)`

**给字段添加索引**
1. `普通索引` 是最基本的索引，没有任何限制 添加了索引的字段的值可以为空
2. `唯一索引` 字段的值可以=null，唯一索引列的值必须唯一
3. `主键索引` 是特殊的唯一索引，一张表只能有一个主键，不能为空
4. `联合索引` 注意与 联合主键区分开

`哪个是b树 b+树 要会区分：`b+树只有叶子节点存储表真实数据 非叶子结点只存储目录页数据。所以比b树更矮胖 io次数更少  
`隐藏索引` 不使用索引了 但是此时 索引的结构还会随增删改查变化!!!

**索引的三级结构**
`索引(b+树)` -> `索引节点(索引节点是数据页) 关注页结构` -> `叶子节点数据页里面是真实数据 关注行格式`

**mysql主要关心(面试4大重点)**
1. 索引
2. sql优化 (为了快)
3. 事务
4. 锁 (为了数据准确)

**hash索引和b+树索引区别**(底层数据结构、增上改查性能、磁盘利用率、磁盘随机/顺序访问等方面)
1. hash索引是哈希表结构 hashmap底层也是这个结构 b+树是多路平衡树的结构
2. hash索引这种数据结构决定了hash索引在等值查询有很好的性能 对于范围查询和排序hash索引性能比较差  
   b+树索引在范围查询和排序上更加高效 因为b+树是有序的
3. hash索引插入和删除比较简单 通过hash函数确定索引位置插入即可 删除也是链表所方便的  
   b+树插入删除需要维护树的平衡性 需要节点的拆分和合并 更复杂
4. hash索引对于磁盘利用效率不高 哈希索引数据分布是随机的 会导致磁盘的随机访问  
   b+树节点是有序存储的 有利于磁盘的顺序访问 减少io次数


<span style="color: #90EE90;">**数据库调优相关(实操性)**</span>

mysql理论知识达到一定基础后可以思考mysql调优问题  
**数据库调优的目标(为什么调优)**
1. 尽可能节省系统资源，以便系统可以提供更大负荷的服务(吞吐量更大)
2. 减少系统的瓶颈，提高MySQL数据库整体的性能
3. 合理的结构设计和参数调整，以提高用户操作响应的速度(响应速度更快)

**如何调优**  
1. 以用户的反馈、日志反馈为出发点

**性能分析工具**  
1. sql命令 `SET optimizer_trace="enabled=on";` 以启用`explain trace`。`监控分析视图`就是将分析结果整合更直观的呈现
2. `通过查询mysql一些系统表`：mysql一些系统表会存储冗余索引记录、访问表最频繁的表 可以考虑建立索引
3. 监控sql执行频率

**数据库调优的点**
下面列出的`数据库调优的点`是总结的几乎所有的调优方式，根据具体的情况选择怎样调优  
1. `选择合适的DBMS`
2. `优化mysql参数`
    1. 修改mysql配置文件 my.ini my.cnf:
    2. 缓冲池大小 索引缓冲区大小 同时打开表的个数 查询缓冲区的大小 连接数量
    3. 修改内存刷盘到磁盘的频率 增加索引加载到内存的数据量这样磁盘io减少提升性能
3. `选择合适的存储引擎(数据库层面)`
4. 遵循数据表设计规范：表设计 范式 数据类型的选择(数据表层面)
5. `优化大表` mysql单表记录数过大时，增删改查性能下降。常见优化措施如下：
    1. 限定查询条件 索引
    2. 读写分离(主从复制 双主双从)
    3. 分库分表：一些模块的表在一个主机 另一些模块的表在另一个主机
6. 读写分离(主从复制) 减轻负担
7. 数据分片 分库分表  垂直拆分表(一张表按字段拆分成多张表,冷热数据,平行表的概念) 水平拆分表(比如按年拆分开)
8. 两个表频繁join的 弄到一张中间表的 对于频繁查不更新的
9. 优化数据类型 也是节约索引空间
10. 插入海量数据先停用索引
11. 尽量非空约束
12. 分析表
13. `sql调优(重点)`
    1. 写的sql本地执行一遍，explain看是否符合预期，比如建的索引是否用到了，再看执行时间(排除mysql本身查询缓存的干扰)
    2. 通过mysql理论知识先不用工具肉眼看一下sql可能有的问题  `覆盖索引` `回表` `最左匹配原则`等情况 `索引条件下推`:多个查询条件时 在二级索引中过滤掉不满足的数据，从而减少回表次数
        `前缀索引`：一个字段值过长建索引会占较大空间，因此考虑使用前缀索引，
    3. explain的使用
    4. `如何定位慢sql`：通过慢查询日志文件
    5. `sql物理层面优化`:索引正确使用 针对sql优化中查询优化：进行索引优化 避免索引失效!!!
    6. `sql逻辑层面优化`:优化sql写法:join 子查询优化 排序优化 group by优化 分页查询优化
    7. `sql执行慢可能原因`：
        1. 阻塞了(别的事务锁表)
        2. 没阻塞在执行，单纯执行慢
            - 对于单纯执行慢，首先需要explain分析，还可以执行语句查询sql各操作耗时!!!
            - 索引需要优化 io次数太多 没有索引或`索引失效`：因为删除数据会导致索引树结构不完整，所以一般会逻辑删除为了数据分析、不破坏索引
            - 表字段过多 表设计没遵循数据库表设计规范 第几范式
            - 数据过多
            - sql写的烂，关联查询太多
14. 使用redis辅助
15. 尽量避免排序和全表扫描!!!
16. 为什么尽量 not null 看实际业务需求 如果设置为空带来的影响 好处
    1. 数据完整性
    2. 非空判断需要额外代码校验
    3. 浪费空间
    4. 查询性能
    5. 非空约束是数据库强制校验
17. 思考一下flush操作对其的影响

<span style="color: #90EE90;">**至此数据库调优相关ok**</span>


**explain讲解(查看具体执行计划)**  
mysql优化器会重写sql，如子查询重写为多表连接，explain看到的是重写后的sql的执行计划  
优化器生成最终执行计划由执行器执行  
**explain每一列的含义：**  
`id`  
和select关键字对应  
对于嵌套查询有两个select关键字 有时优化器会优化成多表连接查询因此id值只有一个  
id越大 优先级越高 越先执行  
id每个值 表示一趟独立查询  
`table`  
涉及几个表 - 生成几条记录  
`select_type`  
和小查询对应 用于描述小查询在整体查询中扮演的角色  
`partitions`  

以下列重要：explain观察 看能读懂的经验  
`type`
针对单表的访问方法：system const  eq_ref ref 好  
range index all 不好  
`possible_key`
可能用到的索引  
`key`  
实际用的索引  
`key_len`
主要针对联合索引 值越大越好 通过key_len可以看出联合索引用了哪个字段的索引  

explain发现使用临时表 不好 最好使用索引来替代

`rows` 预估读取的条数 越小越好  
缓存 内存 磁盘 顺序io  
`filtered` 越大越好  
`extra`：一些额外的信息 会显示是不是文件排序 没借助到索引  
explain的4中输出方式  
至此explain相关ok!!!  


**一些优化案例分析**
**对于多表连接的sql怎么加索引(sql join写法和索引的影响):**  
对于内连接的sql  
对于内连接来说，查询优化器可以决定谁作为驱动表，谁作为被驱动表出现的  
对于内连接来讲，如果表的连接条件中只能有一个字段有索引，则有索引的字段所在的表会被作为被驱动表  
对于内连接来说，在两个表的连接条件都存在索引的情况下，会选择小表作为驱动表。“小表驱动大表”  
对于左外连接的sql 给被驱动表连接条件的字段加索引 会提升sql查询速度  

多表连接的连接字段需要使用索引!!!

**join语句原理：-144**

**sql limit order by写法和索引的影响:**
查询所有字段排序不加limit 索引失效  
查询排序字段排序不加limit 使用索引 覆盖索引：查询不需要回表找数据就能返回结果  
查询所有字段排序加limit 使用索引 (优化器的分析)  
order by时规则不一致，索引失效(顺序错，不索引。方向反，不索引)  

所有的排序都是在条件过滤之后才执行的。所以，如果条件过滤掉大部分数据的话，  
剩下几百几干条数据进行排序其实并不是很消耗性能，即使索引优化了排序，但实际提升性能很有限。  
相对的 stuno<101000这个条件，如果没有用到索引的话，要对几万条的数据进行扫描，这是非常消耗性能的，  
所以索引放在这个字段上性价比最高，是最优选择。  

**索引条件下推(ICP) 参数控制是否使用此策略**
对于索引失效的条件 在索引中继续过滤 从而提升性能  
对于原本索引失效的字段 先不回表 继续在二级索引中查找以提升性能  

**count(*)=count(1)**
count(具体字段)是二级索引 比 count(id)聚簇索引占用内存空间小  
不建议select(*)的原因 会先查数据字典耗时 不能用覆盖索引了  
limit 1不会全表扫描了 limit 1对于唯一索引就不用limit 1了  
看对mysql的理解有多深刻  


**数据库主键如何设计-150 面试官看他懂不懂 对这个的理解和思考**  
`自增id(有很大弊端)`  
1. 安全性不高 很容易泄露总用户量有多少
2. 是在数据库服务器中生成 性能不高
3. 要想知道数据库自增id是多少 还需要多访问一下数据库
4. 自增id在分布式实例下id重复!!!(最重要的问题)
`业务字段做主键(不建议)` 不适合做主键 主键应该无业务含义的

非核心业务表且不涉及id因分布式而重复 则自增id尚可，对于核心业务：主键设计至少应该是全局唯一且是单调递增  
全局唯一保证在各系统之间都是唯一的，单调递增是希望插入时不影响数据库性能  
因此，推荐最简单的一种主键设计：有序UUID!!!  

**-151 范式**  
数据表的设计规范：`数据冗余小`，`结构合理`  
关系型数据库有6大范式 满足第3范式则一定也满足第2范式!!!  
几个术语：`超键` `候选键` `主键` `主属性` `非主属性`  
1. `第一范式(1NF)`要求属性值原子性不能再拆分  
    要求表每个属性值具有`原子性`不能再拆分了 能不能拆分是具备主观性的 根据业务看拆不拆
2. `第二范式(2NF)`业务表的原子性  
    第二范式要求，在满足第一范式的基础上，还要满足数据表里的每一条数据记录，都是可唯一标识的。  
    而且所有非主键字段，都必须完全依赖主键，不能只依赖主键的一部分  
    如果某一字段只通过联合主键其一字段即可确定则不完全依赖则不满足2范式
    第二范式就是 选择的主键或联合主键要能唯一标识记录 即选择的主键或联合主键是正确的 要选对
    **第二范式就是要求业务表的原子性!!! 不能学生表、课程表放到同一张表里!!!**  
3. `第三范式(3NF)`员工表里不能还有部门名称  
    非主属性之间相互独立 不相互依赖 员工表里不能还有部门名称  
    范式本身没有优劣之分，只有适用场景不同。没有完美的设计，只有合适的设计  
    我们在数据表的设计中，还需要根据需求将范式和反范式混合使用  
    具体问题具体分析  
4. `反范式化` 业务优先原则 反范式化也有弊端
    1. 为满足某种商业目标，数据库性能比规范化数据库更重要
    2. 在数据规范化的同时，要综合考虑数据库的性能
    3. 通过在给定的表中插入计算列，以方便查询
    4. 通过在给定的表中添加额外的字段，以大量減少需要从中搜索信息所需的时间

5. `巴斯范式`
6. `第四范式`
7. `第五范式(完美范式)` 多对多拆成三张表？

**ER模型**-156 实体 属性 关系  
强实体：商品分类 唱片公司  
项目大需要涉及很多表时最好做er模型  
er模型转成数据库表结构：实体转成表 多对多也转换成表  

**其他数据表设计原则仅供参考**
数据表越少、字段越少越好，如果使用联合主键 联合主键中的字段越少越好  
主键外键越多越好  

### 事务篇-161 事务 锁 mvcc 事务日志
**事务概述**
事务 提交之后事务就结束了  
事务是一组操作的集合，要么全部成功，要么全部失败。不能被中断的。  
多个连接到mysql可能对应多个事务 一段Java代码里的dml也可能不在一个mysql事务里;  

**事务四大特性**  
1. 原子性(A)
2. 一致性(C)：事务执行前后 数据合法状态到另一个数据合法状态 执行时可能是数据不合法的 没事!!!
3. 隔离性(I)：
    事务的隔离性是指一个事务的执行 不能被其他事务干扰  
    即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。  
    相当于线程安全  
4. 持久性(D)： 永久保存到数据库中

**事务状态：(5个)**  
`活动的` `部分提交` `失败的` `中止的(最终状态)` `提交的(最终状态)`

**事务的完整过程**
1. 开启事务
2. 一系列dml
3. 事务结束的状态 `提交(commit)` `中止(rollback)`
`保存点` 回滚到事务某一步骤  

**显式事务(显式开启一个事务)**  
begin;不自动提交  
**隐式事务**
默认自动提交时 每个dml都是一个事务  
ddl 是隐式事务!!!  
begin dml dml 又begin 此时会隐式提交上一个事务  
使用LOCK TABLES、UNLOCK TABLES 等关于锁定的语句也会 隐式的提交 前边语句所属的事务  


没commit也会查到数据!!!  
completion=1，这种情況下，当我们提交事务后，相当于执行了 COMMIT AND CHAIN，  
也就是开启一个链式事务，即当我们提交事务之后会开启一个相同隔离级别的事务。  
myisam存储引擎不支持事务!!!  


**并发事务引发的问题**
1. 脏写(Dirty Write 丢失修改)
    没写成功  
    对于两个事务 Session A、Session B，  
    如果事务Session A 修改了 另一个 未提交 事务Session B修改过的数据，那就意味着发生了脏写，  
    两个事务同时写同一个数据，提交的数据被另一个事务回滚掉了，产生脏写!!!  
2. 脏读
    读的错误 事务a没提交的数据被另一个事务读到 后来事务a回滚
3. 不可重复读
    一个事务里多次读一个值竟然都不一样 别的事务干扰
4. 幻读
    一个事务里多次查询竟然每次行数都不一样 别的事务干扰

事务并发问题都解决了会导致并发性能不好 都不解决并发性好了但是隔离性不好数据有问题  
所以要平衡 即事务隔离级别要适度，再配合锁的使用  
事务并发问题严重性:脏写(最严重) > 脏读 > 不可重复读 > 幻读  

事务在service层定义，一个service层的方法通常是执行了几个dao层函数，即执行了几条sql  
**事务隔离性**
**事务4个隔离级别(一个全局或会话变量)：当多个事务并发访问数据库时，这些事务之间要有所隔离，即互不干扰：**
1. `读取未提交`： 允许读没提交的，设置该隔离级别脏读、幻读、不可重复读依然会存在
2. `读取已提交`： 允许读已提交的 设置该隔离级别 脏读问题不会有了
3. `可重复读`：(mysql默认级别  mysql该级别并发问题都解决了!!!) 设置这个隔离级别 脏读 不可重复读不会有了 如果该级别想避免幻读需要手动加锁!!!
4. `可串行化`：(隔离级别最高 并发性最差) 问题都没有了 咋做的？行独占锁

这4个事务隔离级别分别能防止哪些并发事务问题，这也是知识点。  
查看mysql某版本某存储引擎默认的事务隔离级别  
修改事务隔离级别可以是全局/会话级别的 内存级别的 重启不行了 要改配置文件  


**事务日志-169**  
事务有4大特性，其中`事务隔离性`是`锁`机制实现的!!!其余3个特性是 事务日志 保证的!!!  
事务日志(2种)
1. `REDO LOG(重做日志)` redo日志就是内存做的事的全方位及时跟踪记录 复刻!!!  
    提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性!!!  
    内存数据记录到 redolog 保证能同步到磁盘 宕机也没事 也是一种数据恢复行为!!!  
    物理级别的修改  
    是存储引擎层(innodb)生成的日志，记录的是”物理级别“上的页修改操作，比如页号xxx、偏移量yyy写入了'zzz数据  
    主要为了保证数据的可靠性。  
    内存的修改 同步到redo日志 以同步到磁盘  

2. `UNDO LOG(回滚日志)`
    回滚行记录到某个特定版本，用来保证事务的原子性、一致性!!!  
    能保证出错回滚 UNDO LOG记录修改前的数据 用于修改数据的恢复 撤销!!! undo log记录一个反方向的操作改回去!!!  
    是存储引擎层(innodb)/生成的日志，记录的是 逻辑操作日志1比如对某一行数据进行了INSERT语句操作，那么undo log就记录一条与之相反的DELETE操作。  
    undo log主要用于  
    1. 事务的回滚(undo 1og记录的是每个修改操作的逆操作)  
    2. 一致性非锁定读(undo log 回滚行记录到某种特定的版本---MVCC，即多版本并发控制)。  
    都是存储引擎层生成的日志 redo undo不是互逆过程 undo也不是逆向操作 是正向 逻辑逆向操作  
    undo的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成   
    当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo。读取之前的行版本信息，以此实现非锁定读取。  


mysql变量 innodb_flush_log_at_trx_commit
为什么不需要undo log buffer？


**锁**-173
mysql事务隔离性是`锁`机制实现的!!!有几个事务 - 有几个锁结构 锁结构:锁的事务信息 是否等待  
锁这个概念编程 数据库都有这个概念 锁机制解决并发问题 数据的准确性  
`数据准确性` `并发性能` 二者权衡  

**事务并发场景**  
1. `读读情况` ok  不会有问题
2. `写写情况` 有脏写问题 但数据库帮助解决了 因此ok 不会有问题
3. `读写情况` 只有该情况需要手动处理 有脏读 幻读 不可重复读问题!  
    解决方案：  
    1. 读mvcc(只能读到生效的数据) 写加锁  
    2. 读写都加锁 性能略低 读数据也加锁 读数据最新版本  


**锁的分类**
锁的个数是有限的 锁空间占内存空间 超出限度会自动锁升级!!!

**按数据操作类型**
- `读锁(共享锁s)` 共享锁占用时 排他锁需要等待 lock in share mode 共享锁之间兼容
- `写锁(排他锁x)` 广义加锁加的是排他锁 读的时候也会加排他锁 for update sx锁均可以加在表、行上

**按锁粒度**
1. `表锁` 不建议innodb加
    1. `共享锁`
    2. `排他锁`
    3. `意向锁` 排他锁行锁加上之后会自动给所在表加一个表级锁即意向排他锁 合理 表的加锁标记 行级锁和表级锁可以共存
    4. `自增锁(了解)`
    5. `元数据锁MDL` 当对一个表做增删改查操作的时候，加MDL读锁 当要对表做结构变更操作的时候，加MDL写锁(ddl时dml ddl会阻塞)!!!
2. `页级锁(了解)` 锁数据页 也会死锁 互相锁数据页
3. `行锁`
    1. `记录锁` 锁开销大 有死锁问题 也有读写锁之分 事务里写操作时自动加行锁排他锁!!!
    2. `间隙锁`
        1. 针对幻读问题产生幻影记录 间隙锁的读写锁没区别
        2. 查不存在的id自动产生区间的间隙锁 防止其他事务插入该区间id记录
        3. 间隙锁可能导致死锁(两个事务同时读 再同时插入数据 会死锁!!!) 死锁:互相等待并且都释放不了
        4. mysql发现死锁自动回滚一个成本低的事务
    3. `临键锁` 作用=记录锁+间隙锁 自动加的
    4. `插入意向锁` 插入失败等待的事务也产生锁-插入意向锁 不是意向锁  两个插入意向锁之间不冲突

**按锁态度**(需要注意的是，乐观锁和悲观锁并不是锁，而是锁的设计思想)
1. `悲观锁(适用写多读少)` 自己事务使用时先加排他锁，其他线程阻塞，并发性能差
2. `乐观锁(适用读多写少 无死锁)`
    乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件  
    不用每次都对数据上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，  
    也就是不采用数据库自身的锁机制，而是通过程序来实现!!!  
    在程序上，我们可以采用
    1. 版本号机制(读写时都在最新版本数据基础上) 时间戳机制  被改过时间戳会更新 到时候对比时间戳!!!
    2. CAS机制 实现 在Java中 java.util.concurrent.atomic包下的原子变量类就是使用了乐观锁的一种实现方式：CAS实现的。
   

**按加锁方式**
1. `隐式锁(了解)` 别的事务在事务没结束时访问时才加锁 会延时加锁
2. `显式锁` 语句显式加的 能查到的 都叫显式锁

**其他的锁**
1. `全局锁`:锁整个数据库 一般在数据库迁移时使用
2. `死锁` 行锁 页锁会有死锁,死锁检测机制 自动 看有没有环出现  
    如何避免死锁： 合理设计索引，使业务 SQL尽可能通过索引定位更少的行，减少锁竞争!!!


**锁内部结构 锁产生在内存中**

**锁监控**
1. InnoDB_row_1ock状态变量 注意百度 锁等待时间
2. performance_schema.data_lock_waits表


**MVCC**-183 实际开发不涉及 八股文可以不会 但是能实操使系统性能提升  
`多版本并发控制` 只能读到最新版本且生效的数据!!!写的时候 mvcc会使用`写时复制技术`:类似git创建多个分支 同时修改 然后合并 `乐观锁`  
事务的过程中`数据一致性`是不保证的 但其他事务因为mvcc可以一致性读 读到事务之前的数据!!!  
做到即使有读写冲突时，也能做到 不加锁，非阻塞并发读，而这个读指的就是`快照读`，而非`当前读`，这就是mvcc实现的效果!!!  
当前读实际上是一种加锁的操作，是悲观锁的实现。而MVCC本质是采用乐观锁思想的一种方式。  
`当前读`：读数据的最新版本 加锁就是为了读最新版本  
`快照读`：读历史版本或最新版本

**mvcc实现原理(3块)**
1. 每次增删改的时候 undo log都记录了
2. 行格式隐藏字段
3. read view


**行格式隐藏字段**
1. `事务id` (该写操作所在事务id)
2. `回滚指针` 事务之前的状态 只针对未提交时
    每次对记录进行改动，都会记录一条undo日志，  
    每条undo日志也都有一个ro11_pointer 属性(INSERT 操作对应的undo。日志没有该属性，因为该记录并没有更早的版本)，  
    可以将这些undo日志都连起来，串成一个链表：  
    回滚指针指向操作前的数据  

**read view：(mvcc核心实现原理)**
在MVCC 机制中，多个事务对同一个行记录进行更新会产生多个历史快照，这些历史快照保存在 Undo Log 里。  
如果一个事务想要查询这个行记录，需要读取哪个版本的行记录呢？  
这时就需要用到 ReadView 了，它帮我们解决了行的可见性问题。  
Readview 就是事务在使用MVCC机制进行快照读操作时产生的读视图  
当事务启动时，会生成数据库系统当前的一个快照，InnoDB 为每个事务构造了一个数组,  
用来记录并维护系统当前 活跃事务的ID(“活跃”指的就是，启动了但还没提交)。  

mvcc是不用锁 快照读 所以读未提交、可串行化这俩隔离级别和mvcc无关!!!  
读已提交/可重复读这俩级别都和mvcc有关 也就是和readview有关!!!  
扒readview底层实现原理就是八股文 但是知道mvcc做了什么事 解决了什么问题 设计思想是有必要的!!!  
readview解决幻读问题  


### 日志与备份篇-187
日志会降低数据库性能 占空间  
1. `事务redo日志`(保证事务持久化)
2. `事务undo日志`(保证数据一致性 原子性 能回滚)
3. `慢查询日志`
4. `通用查询日志`
    show variables like '%general%'  
    通用查询日志用来 记录用户的所有操作，包括启动和关闭MySQL服务、  
    所有用户的连接开始时间和截止时间、发给 MySQL 数据库服务器的所有SQL指令等  
    当我们的数据发生异常时，查看通用查询日志，还原操作时的具体场景，可以帮助我们准确定位问题。  
5. `错误日志`
6. `二进制日志 bin log`  
    也叫作数据库变更逻辑日志(update log)，它记录了数据库所有执行的DDL和DML等数据库更新事件的语句  
    但是不包含没有修改任何数据的语句(如数据查询语句select.show等)  
    每次重启会新生成二进制日志文件  
    
    一些bin log有关的命令：
    1. 查看bin log有关的系统变量：`show variables like '%log_bin%';` 比如查看是否启用了二进制日志、二进制日志文件位置等
    2. 删除二进制日志文件：
    3. 查看二进制日志文件的内容(原始文件内容为二进制格式 加以格式转换并且格式化了)：`show binlog events in 'atguigu-bin. 000002' from 468 limit 1,3;`
    4. 显示二进制日志文件列表：`show binary logs;`
    5. `flush logs;`：不再使用当前二进制日志文件记录，新建一个二进制日志文件记录。该命令会附带的做bin log刷盘行为

    二进制日志文件数据记录&持久化流程：
    1. bin log写入机制：写入bin log缓存
    2. bin log刷盘机制：binlog缓存内容持久化到磁盘上的二进制日志文件里
    
    二进制日志用于:  
    1. `主从服务器之间的数据同步比如主从复制`
    2. `服务器遇到故障时数据的无损失恢复`
    
    binlog 格式设置方式：
    binlog 格式类型：1.STATEMENT 格式，2.ROW 格式 3.MIXED 格式
    1. 全局设置：`SET GLOBAL binlog_format = 'ROW';`
    2. 会话设置：`SET SESSION binlog_format = 'ROW';`
    查看binlog格式：`SHOW VARIABLES LIKE 'binlog_format';`

7. `中继日志`：relay log
    中继日志只在主从服务架构的从服务器上存在  
    从服务器为了与主服务器保持一致，要从主服务器读取二进制日志的内容，  
    并且把读取到的信息写入 本地的日志文件 中，这个从服务器本地的日志文件就叫 中继日志。  
    然后，从服务器读取中继日志，并根据中继日志的内容对从服务器的数据进行更新，完成主从复制  

**bin log与redo log对比&区别**
`redo log`是物理日志，记录内容是 `在某个数据页上做了什么修改`，是InnoDB `存储引擎层`产生的  
`bin log`是逻辑日志，记录内容是语句的原始逻辑，类似于 `给ID=2这一行的c字段加1`，属于MySQL的`服务层`  
虽然它们都属于持久化的保证，但是则重点不同  
redo log让InnoDB存储引擎拥有了崩溃恢复能力  
binlog保证了MySQL集群架构的数据一致性  
事务只有提交才会写入bin log 。事务里每条语句执行完都会实时写入redo log

假设一个事务，对表做10万行的记录插入，在这个过程中，一直不断的往redolog顺序记录，  
而bin log不会记录，直到这个事务提交，才会一次写入到bin log文件中!!!


**二阶段提交**redo log分两步写!!!
为了确保redo log和bin log数据一致性  
redo log是事务过程实时写入的 bin log是提交之后写入的!!!  
一阶段：一个事务有10个sql 每次sql完事后该操作写入redo log 标记为prepare状态  
二阶段：事务提交时候 事务操作写入bin log 然后把redo log中日志设置为commit状态  
因此 innodb写redo log时候是两阶段的!!!


**mysql主主复制主从复制**(这样同样可以提升数据库的并发处理能力 也是数据库调优方案之一)  
主从复制的作用：读写分离提升并发性能 机制：3个线程

**配置主从复制具体实操**  
有2个数据库实例进程instance1、instance2分别在主机host1、主机host2上  
instance1新建库newdb1，则instance2也新建库newdb1  
instance1原有库A、B、C，instance2也原有库A、B、C。总之让instance1和instance2数据一致。

环境： 2台Linux虚拟主机，版本均为centos6.5，对应2个不同的ip地址，这2台虚拟主机均安装有mysql5.6。

**开始构建主从复制如下4步**
1. `第1步`  
切换用户，service iptables stop以暂时关闭防火墙，chkconfig --level 2345 iptables off以永久关防火墙，ifconfig以看ip地址。  
使2个操作系统下的mysql里没有任何数据，自己不创建任何库，自带的库不用管。  
令主机host1为主数据库服务器，主机host2为从数据库服务器(谁为主无所谓)。  
一般Linux下mysql配置文件在/etc/my.cnf。find / -name my.cnf以查找所有名为my.cnf的文件。vim /etc/my.cnf以打开mysql配置文件，在配置文件中加log-bin=mysql-bin，表示已开启二进制日志，必须开启主服务器二进制日志，因为数据的同步实质为其他的mysql数据库服务器将这个数据变更的二进制日志在本机上再执行一遍，配置文件中保证每台主机的server-id不重复。  
2. `第2步`(在master数据库服务器中)  
进入mysql。  
GRANT REPLICATION SLAVE ON *.* TO '主库用户名'@'从库ip地址' IDENTIFIED BY '主库密码';`创建一个slave主机中可以登录的mysql用户`  
FLUSH PRIVILEGES;  
退出mysql。  
service mysql stop;  
service mysql start;  
3. `第3步`(在master数据库服务器中)  
进入mysql。  
show master status;  
停止服务再启动服务。  
4. `第4步`(在slave数据库服务器中)
进入mysql。  
CHANGE MASTER TO MASTER_HOST='主库ip地址',MASTER_USER='主库用户名',MASTER_PASSWORD='主库密码',  
MASTER_LOG_FILE='mysql-bin.000011',MASTER_LOG_POS=417;  
(在CHANGE MASTER TO之前stop slave;reset slave;)  
START SLAVE;  
SHOW SLAVE STATUS\G  
(养成习惯：改配置文件先停掉服务)

**至此ok开始测试主从复制**
进入主的mysql，show databases，进入从的mysql，show databases。  
进入主MySQL，建库，新库名test，再进入从MySQL，看有没有这一新库test。  
关机后，操作第4步，重启slave数据库服务器以重新开启主从复制。  

**主从复制的问题**
1. 数据一致性问题
2. 数据延迟问题 读操作时从库还没同步成功


**数据库备份与恢复**
1. 逻辑备份数据
2. 逻辑恢复数据
3. 物理备份数据
4. 物理恢复数据
5. 表数据的导出与导入
6. 数据库迁移